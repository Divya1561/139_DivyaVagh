{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "139_Lab3_Task_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNS40bpjbySlDeuRUvRBY+f"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qliZRqMf3y-w"
      },
      "source": [
        "# **Task 2**: Apply algorithm on breast cancer wisconsin dataset - One Hot Encoding of features: and Train test Division 50%-50%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFZtStld4I3Z",
        "outputId": "23487e2b-f6e3-40ef-a375-979b4bac9372"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1PQbOw84bB9"
      },
      "source": [
        "# Importing required libraries\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWbIXkUd4ffn",
        "outputId": "773c7f9d-f5e5-4f78-a4b4-2129ed963944"
      },
      "source": [
        "# Loading dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML/Lab3/breast-cancer-wisconsin-dataset.csv') \n",
        "print(\"\\nData :\\n\", dataset)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data :\n",
            "            id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
            "0      842302         M  ...                  0.11890          NaN\n",
            "1      842517         M  ...                  0.08902          NaN\n",
            "2    84300903         M  ...                  0.08758          NaN\n",
            "3    84348301         M  ...                  0.17300          NaN\n",
            "4    84358402         M  ...                  0.07678          NaN\n",
            "..        ...       ...  ...                      ...          ...\n",
            "564    926424         M  ...                  0.07115          NaN\n",
            "565    926682         M  ...                  0.06637          NaN\n",
            "566    926954         M  ...                  0.07820          NaN\n",
            "567    927241         M  ...                  0.12400          NaN\n",
            "568     92751         B  ...                  0.07039          NaN\n",
            "\n",
            "[569 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU6A0ytK6Zxk"
      },
      "source": [
        "In the above dataset, all the feature values are numbers and the class label is diagnosis (either M or B values).\n",
        "So, there is no need of one hot encoding of features.\n",
        "\n",
        "But I have done label encoding of class labels to avoid ValueError pos_label in precision_score()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-TRpxnZ6iAh"
      },
      "source": [
        "# prepare features set\n",
        "features = dataset.iloc[:, 2:-1].values\n",
        "# print(features)\n",
        "\n",
        "# label encoding\n",
        "le = LabelEncoder()\n",
        "target = le.fit_transform(dataset.iloc[:, 1].values)    # 1 - M, 0 - B\n",
        "# print(target)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU63gk7h6rLR"
      },
      "source": [
        "#import the necessary module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split data set into train and test sets\n",
        "data_train, data_test, target_train, target_test = train_test_split(features,\n",
        "                        target, test_size = 0.5, random_state = 139)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpERQE5s7FO3",
        "outputId": "e9311fb7-6064-4090-9ab8-908579731dc4"
      },
      "source": [
        "# Training model\n",
        "model = GaussianNB()\n",
        "\n",
        "#Train the model using the training sets\n",
        "model.fit(data_train, target_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3fxUPuI7J_E"
      },
      "source": [
        "# Testing model\n",
        "# Division train test is 50 : 50\n",
        "target_pred = model.predict(data_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-P1W0w7UcS",
        "outputId": "b9aa87e4-a362-4168-b532-a30454036fe4"
      },
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy: \", accuracy_score(target_test, target_pred))\n",
        "\n",
        "# Precision\n",
        "print(\"Precision: \", precision_score(target_test, target_pred))\n",
        "\n",
        "# Recall\n",
        "print(\"Recall: \", recall_score(target_test, target_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"Confusion matrix: \")\n",
        "confusion_matrix(target_test, target_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9543859649122807\n",
            "Precision:  0.9807692307692307\n",
            "Recall:  0.9026548672566371\n",
            "Confusion matrix: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[170,   2],\n",
              "       [ 11, 102]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}